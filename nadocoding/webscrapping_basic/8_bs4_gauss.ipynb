{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('cpv': conda)"
  },
  "interpreter": {
   "hash": "e25e0584590c458883016a89e0cf53be7d76548718d22946ce414c44a74f5c84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "마지막 화의 제목 가져오기 :  후기 + 10년 후 가우스\n마지막화 링크 정보 :  /webtoon/detail.nhn?titleId=675554&no=911&weekday=mon\n수정한 마지막화 링크 정보 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=911&weekday=mon\n"
     ]
    }
   ],
   "source": [
    "#가우스전자 실습\n",
    "#가우스전자의 제목과 링크를 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://comic.naver.com/webtoon/list.nhn?titleId=675554\" #가우스 전자\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"lxml\") \n",
    "\n",
    "#a태그만으로는 정보가 없다. td태크의 클래스가 title인 것들로 시도를 해봐야 한다.\n",
    "\n",
    "#마지막 화의 제목 가져오기\n",
    "cartoons = soup.find_all(\"td\", attrs={\"class\":\"title\"})\n",
    "title = cartoons[0].a.get_text()        #리스트형식이므로 [0] 이 즉 첫번째 제목\n",
    "#즉, td태크 + 클래스:타이틀을 다 긁어서 cartoons에 저장하고,title을 cartoons의 첫번째 텍스트로저장\n",
    "\n",
    "print(\"마지막 화의 제목 가져오기 : \", title)        #후기 + 10년 후 가우스\n",
    "\n",
    "#링크를 사용하기 위해 링크 정보 가져오기 => td밑의 a태그의 href 속성이 필요하다.\n",
    "#<a href=\"/webtoon/detail.nhn?titleId=675554&amp;no=911&amp;weekday=mon\" onclick=\"nclk_v2(event,'lst.title','675554','911')\">후기 + 10년 후 가우스</a> 여기서 href부분이 필요하다는 의미\n",
    "\n",
    "link = cartoons[0].a[\"href\"]      #모든 정보를 갖고있는 cartoons의 a태크의 [href]부분의 첫번째 링크!\n",
    "print(\"마지막화 링크 정보 : \", link)                   \n",
    "#/webtoon/detail.nhn?titleId=675554&no=911&weekday=mon 밖에 없으므로 수정(http등등이 필요하다.)\n",
    "\n",
    "print(\"수정한 마지막화 링크 정보 : \", \"https://comic.naver.com\" + link)   \n",
    "#https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=911&weekday=mon 로 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "제목 :  후기 + 10년 후 가우스      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=911&weekday=mon\n제목 :  시즌4 430화 내일 봐요      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=910&weekday=mon\n제목 :  시즌4 429화 잠행      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=909&weekday=mon\n제목 :  시즌4 428화 추억      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=908&weekday=mon\n제목 :  시즌4 427화 섬세한사람      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=907&weekday=mon\n제목 :  시즌4 426화 적응      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=906&weekday=mon\n제목 :  시즌4 425화 대견      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=905&weekday=mon\n제목 :  시즌4 424화 초빙강사      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=904&weekday=mon\n제목 :  시즌4 423화 추억의 물건      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=903&weekday=mon\n제목 :  시즌4 422화 아니요      그리고 링크 :  https://comic.naver.com/webtoon/detail.nhn?titleId=675554&no=902&weekday=mon\n"
     ]
    }
   ],
   "source": [
    "#한 페이지의 모든 링크, 제목 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://comic.naver.com/webtoon/list.nhn?titleId=675554\" #가우스 전자\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"lxml\") \n",
    "cartoons = soup.find_all(\"td\", attrs={\"class\":\"title\"})\n",
    "\n",
    "for cartoon in cartoons:\n",
    "    title = cartoon.a.get_text()      #제목 정보\n",
    "    link = \"https://comic.naver.com\" + cartoon.a[\"href\"]  #링크 정보\n",
    "    print(\"제목 : \", title + \"      그리고 링크 : \", link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.98\n9.98\n9.97\n9.97\n9.97\n9.98\n9.97\n9.97\n9.97\n9.97\n전체점수 :  99.72999999999999\n평균점수 :  9.972999999999999\n"
     ]
    }
   ],
   "source": [
    "#평균 평점 구하기\n",
    "\n",
    "#태그명이 div 클래스가 rating_type\n",
    "#우리가 필요한 것은 strong태그의 숫자값만 필요하다.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://comic.naver.com/webtoon/list.nhn?titleId=675554\" #가우스 전자\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"lxml\") \n",
    "cartoons = soup.find_all(\"div\", attrs={\"class\":\"rating_type\"})\n",
    "\n",
    "#평점 구하기\n",
    "total_rates = 0\n",
    "for cartoon in cartoons:\n",
    "    rate = cartoon.find(\"strong\").get_text() \n",
    "    #★★★★우리가 필요한 것은 strong태그의 숫자값만 필요하다. 이러면 cartoon 객체에서 strong element만 가져올 것이다. \n",
    "    print(rate)  #굳이 필요없음\n",
    "    total_rates += float(rate) #9.97이므로 실수형으로 변헝\n",
    "\n",
    "print(\"전체점수 : \", total_rates)                   #전체점수 :  99.72999999999999\n",
    "print(\"평균점수 : \", total_rates / len(cartoons))   #평균점수 :  9.972999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#터미널에서 하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.coupang.com/np/search?q=%EB%85%B8%ED%8A%B8%EB%B6%81&channel=user&component=&eventCategory=SRP&trcid=&traid=&sorter=scoreDesc&minPrice=&maxPrice=&priceRange=&filterType=&listSize=36&filter=&isPriceRange=false&brand=&offerCondition=&rating=0&page=1&rocketAll=false&searchIndexingToken=1=4&backgroundColor=\"\n",
    "\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "print(res.text)"
   ]
  }
 ]
}