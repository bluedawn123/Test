{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('cpv': conda)"
  },
  "interpreter": {
   "hash": "e25e0584590c458883016a89e0cf53be7d76548718d22946ce414c44a74f5c84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 헤드라인 뉴스\n",
    "# 1. 무슨 일이 ...\n",
    "#   (링크 : https:// ... )\n",
    "# 3. 무슨 일이 ...\n",
    "#   (링크 : https:// ... )\n",
    "# 2. 무슨 일이 ...\n",
    "#   (링크 : https:// ... ) 형식으로."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "#url 함수\n",
    "def create_soup(url):\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "def scrape_weather():\n",
    "    print(\"[오늘의 날씨]\")\n",
    "    url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%84%9C%EC%9A%B8+%EB%82%A0%EC%94%A8\"\n",
    "    soup = create_soup(url)\n",
    "\n",
    "    #맑음, 어제보다 0˚ 높아요\n",
    "    cast = soup.find(\"p\", attrs={\"class\":\"cast_txt\"}).get_text()\n",
    "    \n",
    "    #현재 00도˚\n",
    "    curr_temp = soup.find(\"p\", attrs={\"class\":\"info_temperature\"}).get_text().replace(\"도씨\", \"\")\n",
    "    #\"p\", attrs={\"class\":\"info_temperature\"부분의 글자를 다 긁어오면 너무 기니깐 도씨를 제외하는 방법\n",
    "    min_temp = soup.find(\"span\", attrs={\"class\":\"min\"}).get_text()\n",
    "    max_temp = soup.find(\"span\", attrs={\"class\":\"max\"}).get_text()\n",
    "\n",
    "    # 오전 강수확률 00% / 오후 강수확률 00%\n",
    "    morning_rain_rate = soup.find(\"span\", attrs={\"class\":\"point_time morning\"}).get_text().strip()  #strip으로 공백제거\n",
    "    afternoon_rain_rate = soup.find(\"span\", attrs={\"class\":\"point_time afternoon\"}).get_text().strip()  #strip으로 공백제거\n",
    "\n",
    "    #미세먼지, 초미세먼지 => indicate정보를 가지고, dd엘리먼트를 갖고 순차적으로 찍어주는 방식으로 실행해보자\n",
    "    dust = soup.find(\"dl\", attrs={\"class\":\"indicator\"})      #먼지  \n",
    "    fine_dust = dust.find_all(\"dd\")[0].get_text()            #미세먼지    dust(dl태그, 클래스)에서 dd인것을 다 찾고 거기서 1번째 텍스트\n",
    "    worse_find_dust = dust.find_all(\"dd\")[1].get_text()      #초미세먼지  dust(dl태그, 클래스)에서 dd인것을 다 찾고 거기서 2번째 텍스트\n",
    "   \n",
    "\n",
    "    #출력\n",
    "    print(\"cast : \", cast)\n",
    "    print(\"현재 {} (최저 {} /  최고 {})\".format(curr_temp, min_temp, max_temp))\n",
    "    print(\"오전 {} / 오후 {}\".format(morning_rain_rate, afternoon_rain_rate))\n",
    "    print(\" \")\n",
    "    print(\"미세먼지 {}\".format(fine_dust))\n",
    "    print(\"현재 {} (최저 {} /  최고 {})\".format(curr_temp, min_temp, max_temp))\n",
    "    print(\"오전 {} / 오후 {}\".format(morning_rain_rate, afternoon_rain_rate))\n",
    "    print(\" \")\n",
    "    print(\"미세먼지 {}\".format(fine_dust))\n",
    "    print(\"초미세먼지 {}\".format(worse_find_dust))\n",
    "\n",
    "\n",
    "def scrape_headline_news():\n",
    "    print(\"[헤드라인 뉴스]\")\n",
    "    url = \"https://news.naver.com/\"\n",
    "    soup = create_soup(url)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":     #여기서 직접 실행시만 실행되고, 호출시는 실행 안된다.\n",
    "    scrape_weather()           #오늘의 날씨정보 가져오기"
   ]
  }
 ]
}