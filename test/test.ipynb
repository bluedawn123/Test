{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fa422f78b08b4ed23ea77d9d51ba71e035ebabb7673f323e99ba8b680a1634b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# python\r\n",
    "#1.데이터\r\n",
    "import numpy as np #numpy를 import 하고 numpy의 이름을 np로 줄여서 쓴다.\r\n",
    "x = np.array([1,2,3,4,5,6,7,8,9,10]) #정제된 데이터\r\n",
    "y = np.array([1,2,3,4,5,6,7,8,9,10])\r\n",
    "\r\n",
    "\r\n",
    "print(\"x.shape : \", x.shape)                          \r\n",
    "print(\"y.shape : \", y.shape)\r\n",
    "print(x)\r\n",
    "print(y)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#2. 모델구성\r\n",
    "from keras.models import Sequential #Sequential:순차적 모델을 만든다.\r\n",
    "from keras.layers import Dense #Dense:1차함수 \r\n",
    "\r\n",
    "model = Sequential() #순차적 모델의 모델명\r\n",
    "model.add(Dense(1, input_dim = 1, activation='relu'))\r\n",
    "\r\n",
    "#3. 훈련\r\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy']) #손실을 줄이기위해 mse 사용 adam=최적화 metrics=훈련상황을 모니터링\r\n",
    "model.fit(x,y,epochs=50,batch_size = 1) #x와 y룰 훈련 /epochs:몇번훈련시킬것인가 /batch size:몇개씩 잘를것인가\r\n",
    "\r\n",
    "#4. 평가 예측\r\n",
    "loss, acc= model.evaluate(x,y,batch_size=1)\r\n",
    "print(\"loss : \", loss)\r\n",
    "print(\"acc : \", acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x.shape :  (10,)\n",
      "y.shape :  (10,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 1ms/step - loss: 2.1894 - accuracy: 0.1087 \n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.6084 - accuracy: 0.2754\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6658 - accuracy: 0.0526\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.8167 - accuracy: 0.0860\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 2.2788 - accuracy: 0.0182\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.4301 - accuracy: 0.2754\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.5630 - accuracy: 0.0678\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.1597 - accuracy: 0.0182\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 1.5743 - accuracy: 0.1390\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.2941 - accuracy: 0.1845\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.4415 - accuracy: 0.0526\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.8811 - accuracy: 0.0678\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.1805 - accuracy: 0.1390\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.0396\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0110 - accuracy: 0.0182\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.5282 - accuracy: 0.1845\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.7337 - accuracy: 0.1087\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4713 - accuracy: 0.1845\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5382 - accuracy: 0.1390\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.4155 - accuracy: 0.1845\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5241 - accuracy: 0.0678\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3040 - accuracy: 0.2754\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.0283\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.4383 - accuracy: 0.1390\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3752 - accuracy: 0.0860\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3201 - accuracy: 0.1845\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1528 - accuracy: 0.0283  \n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.1500 - accuracy: 0.0283  \n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.1688 - accuracy: 0.1087\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.0860\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0669 - accuracy: 0.1390\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.1212 - accuracy: 0.1845\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0520 - accuracy: 0.0396\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1077 - accuracy: 0.1390\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0974 - accuracy: 0.0526\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.0967 - accuracy: 0.0396\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.1845\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0354 - accuracy: 0.0678\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0297 - accuracy: 0.0678\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0502 - accuracy: 0.2754\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0576 - accuracy: 0.1390\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0343 - accuracy: 0.1845\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.0860\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.0464 - accuracy: 0.0182\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.1087\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.0678\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.0282 - accuracy: 0.1087\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0276 - accuracy: 0.0182\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0167 - accuracy: 0.0678  \n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0194 - accuracy: 0.0182\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.0182 - accuracy: 0.1000\n",
      "loss :  0.01815292239189148\n",
      "acc :  0.10000000149011612\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}