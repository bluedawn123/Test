{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "'''\r\n",
    "이번 챕터에서는 캐글에서 제공하는 정상 메일과 스팸 메일이 섞여져 있는 스팸 메일 데이터를 가지고, \r\n",
    "데이터에 대한 전처리를 진행하고 바닐라 RNN(Vanilla RNN)을 이용한 스팸 메일 분류기를 구현해보겠습니다.\r\n",
    "'''\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "#%matplotlib inline\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import urllib.request\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "\r\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\", filename=\"spam.csv\")\r\n",
    "data = pd.read_csv('spam.csv',encoding='latin1')\r\n",
    "#다운로드 받은 spam.csv 파일을 Pandas를 이용하여 data에 저장합니다. 총 샘플의 수를 확인해봅시다.\r\n",
    "\r\n",
    "print('총 샘플의 수 :',len(data))   #총 샘플의 수 : 5572"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 샘플의 수 : 5572\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#상의 5개만 출력해보자.\r\n",
    "data[:5]\r\n",
    "\r\n",
    "#상위 5개를 출력해보면, 이 데이터에는 총 5개의 열이 있는데, 여기서 Unnamed라는 이름의 3개의 열은 텍스트 분류를 할 때 불필요한 열  => 삭제 해야한다.\r\n",
    "#v1열은 해당 메일이 스팸인지 아닌지를 나타내는 레이블에 해당되는 열입니다.\r\n",
    "#ham은 정상 메일을 의미하고, spam은 스팸 메일을 의미합니다.\r\n",
    "#v2열은 메일의 본문"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#레이블과 메일 내용이 담긴 v1열과 v2열만 필요하므로, Unnamed: 2, Unnamed: 3, Unnamed: 4 열은 삭제합니다. \r\n",
    "#또한, v1열에 있는 ham과 spam 레이블을 각각 숫자 0과 1로 바꾸겠습니다. 그 후 다시 data에서 5개의 행만 출력해보겠습니다.\r\n",
    "\r\n",
    "#3,4,5열 삭제 \r\n",
    "del data['Unnamed: 2']\r\n",
    "del data['Unnamed: 3']\r\n",
    "del data['Unnamed: 4']\r\n",
    "\r\n",
    "#v1 ham, spam을 0, 1 로 변경 후 다시 상위 5개 출력\r\n",
    "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\r\n",
    "data[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#데이터 전반적인 정보를 확인해보자.\r\n",
    "#data.info()\r\n",
    "\r\n",
    "'''\r\n",
    " 0   v1      5572 non-null   int64 \r\n",
    " 1   v2      5572 non-null   object   => 즉, 총 5,572개의 샘플이 존재\r\n",
    " '''\r\n",
    "\r\n",
    "#null값 같은 샘플 있는지 확인해보자.\r\n",
    "data.isnull().values.any()        # false => Null값이 없다. 즉 다 내용이 있다. \r\n",
    "\r\n",
    "#중복값이 있는지 알아보자.\r\n",
    "data['v2'].nunique(), data['v1'].nunique()    #(5169, 2)\r\n",
    "#=> 총 5,572개의 샘플이 존재하는데 v2열에서 중복을 제거한 샘플의 개수가 5,169개라는 것은 403개의 중복 샘플이 존재한다는 의미\r\n",
    "#=> v1열은 0 또는 1의 값만을 가지므로 2가 출력\r\n",
    "\r\n",
    "#중복 샘플 제거\r\n",
    "data.drop_duplicates(subset=['v2'], inplace=True)\r\n",
    "\r\n",
    "#제거 확인\r\n",
    "if len(data) == 5169:\r\n",
    "    print(\"제거 완료\")  #=> 제거 완료"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "제거 완료\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#시각화 및 데이터 분석\r\n",
    "data['v1'].value_counts().plot(kind='bar');\r\n",
    "#즉, 레이블이 대부분 0에 편중되어있는데, 이는 스팸 메일 데이터의 대부분의 메일이 정상 메일임을 의미. \r\n",
    "\r\n",
    "\r\n",
    "#수치로 확인해보겠습니다.\r\n",
    "print(data.groupby('v1').size().reset_index(name='count'))\r\n",
    "'''\r\n",
    "   v1  count\r\n",
    "0   0   4516\r\n",
    "1   1    653 레이블 0은 총 4,516개가 존재하고 1은 653개가 존재. '''"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   v1  count\n",
      "0   0   4516\n",
      "1   1    653\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#데이터 분리. => v2열을 X, v1열을 y로 저장\r\n",
    "X_data = data['v2']\r\n",
    "y_data = data['v1']\r\n",
    "print('메일 본문의 개수: {}'.format(len(X_data)))\r\n",
    "print('레이블의 개수: {}'.format(len(y_data)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "메일 본문의 개수: 5169\n",
      "레이블의 개수: 5169\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#인코딩 과정\r\n",
    "tokenizer = Tokenizer()\r\n",
    "tokenizer.fit_on_texts(X_data)        # 5169개의 행을 가진 X의 각 행에 토큰화를 수행. \r\n",
    "                                      #fit_on_texts() 메서드는 문자 데이터를 입력받아서 리스트의 형태로 변환\r\n",
    "sequences = tokenizer.texts_to_sequences(X_data)  # 단어를 숫자값, 인덱스로 변환하여 저장\r\n",
    "\r\n",
    "print(sequences[:5])  #equences에는 X_data의 단어들이 각 단어에 맵핑되는 정수로 인코딩되어 저장"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[47, 433, 4013, 780, 705, 662, 64, 8, 1202, 94, 121, 434, 1203, 142, 2712, 1204, 68, 57, 4014, 137], [49, 306, 1364, 435, 6, 1767], [53, 537, 8, 20, 4, 1016, 934, 2, 220, 2713, 1365, 706, 2714, 2715, 267, 2716, 70, 2713, 2, 2717, 2, 359, 537, 604, 1205, 82, 436, 185, 707, 437, 4015], [6, 226, 152, 23, 347, 2718, 6, 138, 145, 56, 152], [935, 1, 97, 96, 69, 453, 2, 877, 69, 1768, 198, 105, 438]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#tokenizer의 word_index 속성은 단어와 숫자의 키-값 쌍을 포함하는 딕셔너리를 반환.\r\n",
    "#X_data에 존재하는 모든 단어와 부여된 인덱스를 리턴\r\n",
    "word_to_index = tokenizer.word_index\r\n",
    "#print(word_to_index) \r\n",
    "'''\r\n",
    "{'i': 1, 'to': 2, 'you': 3, 'a': 4, 'the': 5, 'u': 6, 'and': 7, 'in': 8, 'is': 9\r\n",
    ", 'me': 10, 'my': 11, 'for': 12, 'your': 13, 'it': 14, 'of': 15, 'call': 16, \r\n",
    "'have': 17, 'on': 18, '2': 19, 'that': 20, 'now': 21, 'are': 22, 'so': 23, \r\n",
    "'but': 24, 'not': 25, 'or': 26, 'do': 27, 'can': 28, 'at': 29, \"i'm\": 30, 'get': 31, 'be': 32,\r\n",
    "'will': 33, 'if': 34, 'ur': 35, 'with': 36, 'just': 37, 'no': 38, 'we': 39, 'this': 40, \r\n",
    "'gt': 41, '4': 42, 'lt': 43, 'up': 44, 'when': 45, 'ok': 46, 'free': 47, 'from': 48, 'how': 49, \r\n",
    "'go': 50, 'all': 51, 'out': 52, - 이하 생략}'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "'''\r\n",
    "각 단어에 대한 등장 빈도수는 tokenizer.word_counts.items()를 출력으로 확인 가능\r\n",
    "이를 응용하여 빈도수가 낮은 단어들이 훈련 데이터에서 얼만큼의 비중을 차지하는지 확인 가능!\r\n",
    "등장 빈도수가 1회 밖에 되지 않는 단어들이 전체 단어 집합에서 얼만큼의 비율을 차지하며, \r\n",
    "전체 훈련 데이터에서 등장 빈도로 얼만큼의 비율을 차지하는지 확인해보자.\r\n",
    "'''\r\n",
    "threshold = 2\r\n",
    "total_cnt = len(word_to_index) # 단어의 수\r\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\r\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\r\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\r\n",
    "\r\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\r\n",
    "for key, value in tokenizer.word_counts.items():\r\n",
    "    total_freq = total_freq + value\r\n",
    "\r\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면.(2개이하, 즉 1개면)\r\n",
    "    if(value < threshold):\r\n",
    "        rare_cnt = rare_cnt + 1\r\n",
    "        rare_freq = rare_freq + value\r\n",
    "\r\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\r\n",
    "print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\r\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\r\n",
    "\r\n",
    "'''\r\n",
    "등장 빈도가 1번 이하인 희귀 단어의 수: 4908\r\n",
    "단어 집합(vocabulary)에서 희귀 단어의 비율: 55.02242152466368\r\n",
    "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.082538108811501 의 결과.\r\n",
    "\r\n",
    "등장 빈도가 threshold 값인 2회 미만. 즉, 1회 밖에 되지 않는 단어들은 단어 집합에서 무려 절반 이상을 차지합니다. \r\n",
    "하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 6%밖에 되지 않습니다. \r\n",
    "만약, 이러한 분석을 통해 등장 빈도가 지나치게 낮은 단어들은 자연어 처리에서 제외하고 싶다면 \r\n",
    "케라스 토크나이저 선언 시에 단어 집합의 크기를 제한할 수 있었다는 사실을 기억합시다. \r\n",
    "(정수 인코딩 챕터 참고) 가령, 아래의 코드로 등장 빈도가 1회인 단어들을 제외할 수 있다.'''\r\n",
    "\r\n",
    "#tokenizer = Tokenizer(num_words = total_cnt - rare_cnt + 1)로 할 수 있으나. 여기선 하지 않겠다.\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "등장 빈도가 1번 이하인 희귀 단어의 수: 4908\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 55.02242152466368\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.082538108811501\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n등장 빈도가 1번 이하인 희귀 단어의 수: 4908\\n단어 집합(vocabulary)에서 희귀 단어의 비율: 55.02242152466368\\n전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.082538108811501 의 결과.\\n\\n등장 빈도가 threshold 값인 2회 미만. 즉, 1회 밖에 되지 않는 단어들은 단어 집합에서 무려 절반 이상을 차지합니다. \\n하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 6%밖에 되지 않습니다. \\n만약, 이러한 분석을 통해 등장 빈도가 지나치게 낮은 단어들은 자연어 처리에서 제외하고 싶다면 \\n케라스 토크나이저 선언 시에 단어 집합의 크기를 제한할 수 있었다는 사실을 기억합시다. \\n(정수 인코딩 챕터 참고) 가령, 아래의 코드로 등장 빈도가 1회인 단어들을 제외할 수 있다.'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#단어 집합의 크기를 vocab_size에 저장. 주의할 점은 패딩을 위한 토큰인 0번 단어를 고려하며 +1을 해서 저장해\r\n",
    "vocab_size = len(word_to_index) + 1  \r\n",
    "print('단어 집합의 크기: {}'.format((vocab_size)))\r\n",
    "\r\n",
    "n_of_train = int(len(sequences) * 0.8)\r\n",
    "n_of_test = int(len(sequences) - n_of_train)\r\n",
    "print('훈련 데이터의 개수 :',n_of_train)\r\n",
    "print('테스트 데이터의 개수:',n_of_test)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fa422f78b08b4ed23ea77d9d51ba71e035ebabb7673f323e99ba8b680a1634b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}