{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('cpv': conda)"
  },
  "interpreter": {
   "hash": "e25e0584590c458883016a89e0cf53be7d76548718d22946ce414c44a74f5c84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성 공학과 규제\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.4   2.11  1.41]\n [13.7   3.53  2.  ]\n [15.    3.82  2.43]\n [16.2   4.59  2.63]\n [17.4   4.59  2.94]\n [18.    5.22  3.32]\n [18.7   5.2   3.12]\n [19.    5.64  3.05]\n [19.6   5.14  3.04]\n [20.    5.08  2.77]\n [21.    5.69  3.56]\n [21.    5.92  3.31]\n [21.    5.69  3.67]\n [21.3   6.38  3.53]\n [22.    6.11  3.41]\n [22.    5.64  3.52]\n [22.    6.11  3.52]\n [22.    5.88  3.52]\n [22.    5.52  4.  ]\n [22.5   5.86  3.62]\n [22.5   6.79  3.62]\n [22.7   5.95  3.63]\n [23.    5.22  3.63]\n [23.5   6.28  3.72]\n [24.    7.29  3.72]\n [24.    6.38  3.82]\n [24.6   6.73  4.17]\n [25.    6.44  3.68]\n [25.6   6.56  4.24]\n [26.5   7.17  4.14]\n [27.3   8.32  5.14]\n [27.5   7.17  4.34]\n [27.5   7.05  4.34]\n [27.5   7.28  4.57]\n [28.    7.82  4.2 ]\n [28.7   7.59  4.64]\n [30.    7.62  4.77]\n [32.8  10.03  6.02]\n [34.5  10.26  6.39]\n [35.   11.49  7.8 ]\n [36.5  10.88  6.86]\n [36.   10.61  6.74]\n [37.   10.84  6.26]\n [37.   10.57  6.37]\n [39.   11.14  7.49]\n [39.   11.14  6.  ]\n [39.   12.43  7.35]\n [40.   11.93  7.11]\n [40.   11.73  7.22]\n [40.   12.38  7.46]\n [40.   11.14  6.63]\n [42.   12.8   6.87]\n [43.   11.93  7.28]\n [43.   12.51  7.42]\n [43.5  12.6   8.14]\n [44.   12.49  7.6 ]]\n"
     ]
    }
   ],
   "source": [
    "#농어의 특성이 2개에서 3개로 증가.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://bit.ly/perch_csv_data')    #3개 특성 다 있음\n",
    "perch_full = df.to_numpy()\n",
    "print(perch_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
    "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
    "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
    "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
    "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
    "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
    "       1000.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perch_full 과 perch_weight 를 훈련세트와 테스트 세트로 분류\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_poly.shape :  (42, 9)\npolo.get_feature_names() :  ['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2']\n훈련 점수확인 :  0.9903183436982124\ntrain_poly.shape :  (42, 55)\n훈련 점수확인 :  0.999999999997511\n테스트 점수확인 :  -144.40196589599634\n"
     ]
    }
   ],
   "source": [
    "#polynomialfeatures를 통한 특성 증가\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "print(\"train_poly.shape : \", train_poly.shape)                  #(42, 9)  => 특성이 9개로 증가\n",
    "print(\"polo.get_feature_names() : \", poly.get_feature_names())  #['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2'] \n",
    "\n",
    "#다중 회귀 모델 훈련하기 => 다중 회귀 모델 훈련이나 선형 회귀 모델 훈련이나 같다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_poly, train_target)\n",
    "print(\"훈련 점수확인 : \", lr.score(train_poly, train_target))  #점수확인 :  0.999999999997511\n",
    "\n",
    "\n",
    "#특성을 더 추가해보기\n",
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly.fit(train_input)\n",
    "train_poly =  poly.transform(train_input)\n",
    "test_poly = poly.transform(test_input)\n",
    "print(\"train_poly.shape : \", train_poly.shape)      #9특성 => 55개로 증가\n",
    "lr.fit(train_poly, train_target)\n",
    "print(\"훈련 점수확인 : \", lr.score(train_poly, train_target))   #  0.999999999997511 = > .999999999997511\n",
    "print(\"테스트 점수확인 : \", lr.score(test_poly, test_target))  #점수확인 :  -144.40196589599634\n",
    "\n",
    "#특성의 갯수를 늘리면 선형 모델은 강력해진다. 훈련 세트에 대해 다양하고 완벽하게 학습할 수 있기 때문이다. \n",
    "#하지만 이런 모델은 훈련 세트에 과대적합 해지므로 테스트 세트에서는 점수가 안좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#규제 => 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 만드는 것 => 과대적합 방지\n",
    "#선형 회귀 모델의 경우, 특성에 곱해지는 계수의 크기를 줄이는 것.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardscaler를 통한 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_poly)\n",
    "train_scaled = ss.transform(train_poly)\n",
    "test_scaled = ss.transform(test_poly)         #훈련 세트로 학습한 변환기를 사용해 테스트 세트까지 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "릿지 점수 확인 :  0.9896101671037343\n"
     ]
    }
   ],
   "source": [
    "#릿지 회귀\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(train_scaled, train_target)\n",
    "print(\"훈련데이터 릿지 점수 확인 : \", ridge.score(train_scaled, train_target))   #훈련데이터 릿지 점수 확인 :  0.9896101671037343\n",
    "print(\"테스트 데이터 릿지 점수 확인 : \", ridge.score(test_scaled, test_target))   #테스트 데이터 릿지 점수 확인 :  0.979069397761541\n",
    "\n",
    "#alpha 를 매개변수로 규제의 강도를 조절한다. alpha 값이 크면 규제 강도가 세지므로 계수 값을 줄이고 조금 더 과소적합하게 만든다.\n",
    "#alpha 값이 작으면 계수를 줄이는 역할이 줄어들고 선형 회귀 모델과 유사해지므로 과대적합이 될 가능성이 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#적절한 alpha값 찾기\n",
    "#적절한 alpha(하이퍼 파라미터) 값을 찾는 방법 => R2그래프를 그려서 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#담을 그릇으로 list형태 준비\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "for alpha in alpha_list:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(train_scaled, train_target)\n",
    "\n",
    "    #점수저장\n",
    "    train_score.append(ridge.score(train_scaled, train_target))\n",
    "    test_score.append(ridge.score(test_scaled, test_target))\n"
   ]
  }
 ]
}